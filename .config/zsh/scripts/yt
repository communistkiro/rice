#!/bin/zsh
#
# Watch your youtube subscriptions without a youtube account
# via curl, dmenu, mpv and basic unix commands.
#
# The $SUBS_FILE is a text file containing usernames or channel IDs
# comments and blank lines are ignored.
#
# For more information and examples, see:
# http://github.com/mitchweaver/subs
#
# -/-/-/-/- Settings -/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/-/


#yt() {}
typeset SUBS SUBS_FILE SUBS_LINKS SUBS_CACHE SUBS_SLEEP_VALUE;
SUBS=/root/.cache/subs;
SUBS_FILE=${SUBS}/subs.txt;
SUBS_LINKS=${SUBS}/links;
SUBS_CACHE=${SUBS}/cache;
SUBS_SLEEP_VALUE=0.01; # raise this if you experience problems
SEP='^^^^^';
[[ -d ${SUBS} ]] || mkdir ${SUBS};

yt_die () {
  >&2 printf '%s\n' "$*";
  exit 1;
}

# -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
# Synopsis: $SUBS_FILE [txt] -> $SUBS_LINKS [xml links]
#
# Updates local cache of xml subscription links from the
# subscription file containing either usernames or channel ids.
# -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
yt_gen_links () {
  :>$SUBS_LINKS
  typeset line;
  typeset -i count total c;
  count=0;
  total=$(sed -e '/^$/d' -e '/^#/d' < ${SUBS_FILE} | wc -l);
  c=${(c)#$(wc -l < ${SUBS_LINKS})};

  for line ( ${(f)"$(< ${SUBS_FILE})"} ) {
    # ignore comments and blank lines
    case ${line} { (''|' '|'#'*) continue;; };
    # strip off in-line comments and any trailing whitespace
    line=${${line%%#*}%% *};

    printf "[%.${c}d/%.${c}d] fetching channel xml link for %s\n" $((count+=1)) ${total} ${line};

    case ${line} {
      (UC*) # YT channel IDs always begin with 'UC' and are 24 chars long
        ((${#line} == 24)) && {
          printf 'https://youtube.com/feeds/videos.xml?%s\n' channel_id=${line} >> ${SUBS_LINKS};
          continue;
        };;
    };
    # otherwise we are given a username, we must find out its channel ID
    for line ( ${(f)"$(curl -sfL --retry 10 https://youtube.com/user/${line}/about)"} ) {
      case ${line} {
        (*channel/UC??????????????????????*)
          line=${${line##*channel/}%%\"*}
          printf 'https://youtube.com/feeds/videos.xml?channel_id=%s\n' ${line} >> ${SUBS_LINKS}
          break;;
      };
    };
  };
}

# -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
# Synopsis: $1 [LINK] -> $SUBS_CACHE/$chan_name/concat [CHANNEL INFO]
#
# Takes a channel rss feed link and creates a file
# with a line of its videos dates, titles, and urls.
# -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
yt_get_vids () {
  typeset line;
  data=${"$(curl -sfL --retry 15 ${1})"#*\<\/published\>};
  chan=${${data%%\<\/name*}##*name\>};

  for line ( ${(f)data} ) {
    case ${line} {
      (*'link rel='*) url=https://${${${line#*href=\"}%\"/\>}#*www.};;
      (*'<published>'*) date=${${line%+00:*}#*<published>};;
      (*'<media:title>'*) title=${${line%</*}#*:title>}; printf '%s\n' "${date}${SEP}${chan}${SEP}${title}${SEP}${url}" >> ${SUBS_CACHE}/${chan};;
    };
  };
}

# Updates the local cache of subscriptions. ([-u] flag)
yt_update_subs () {
  [[ -f ${SUBS_LINKS} ]] || yt_die 'Subs links have not been generated.'
  typeset link
  typeset -i total count c;

  rm -rf ${SUBS_CACHE} && mkdir ${SUBS_CACHE}

  total=$(wc -l < ${SUBS_LINKS});
  count=0;
  c=${(c)#$(wc -l < ${SUBS_LINKS})};

  for link ( ${(f)"$(< ${SUBS_LINKS})"} ) {
    printf "starting job [%.${c}d/%.${c}d] for %s\n" $((++count)) ${total} ${link};
    yt_get_vids ${link} &;
    sleep ${SUBS_SLEEP_VALUE:-0};
  };

  printf '\n\n%s\n' 'Waiting for jobs to finish...'; wait; printf '%s\n' 'done!';
}

yt_cat_subs () { # grab current cache of subscriptions, sort by date uploaded
    [[ -d ${SUBS_CACHE} ]] ||  yt_die 'Subs cache has not been retrieved.';
    column -t -s '^^^^^' -o ' ' < ${SUBS_CACHE}/* | sort -rk1;
}

yt_get_sel () { # split the concatenated lines into entities, send to selector, and play result w/ mpv
  typeset sel;
  [[ -n ${SUBS_CACHE}/*(#qN) ]] && {
    [[ -t 0 ]] && {
      sel=$(yt_cat_subs | fzy -l ${LINES}) || return 0;
    } || {
      sel=$(yt_cat_subs | dmenu -l 32 -r) || return 0;
    };
  } || yt_die 'Subs cache has not been retrieved.';
  if ((${+dl})) {
    yt-dlp -f bestvideo+bestaudio/best --ignore-errors ${${sel% }##* } & disown || return 1;
  } else {
    { exec mpv ${(z)MPV_OPTS} --pause ${${sel% }##* } } & disown || return 1;
  };
}

yt_main () {
  typeset opt MPV_OPTS;
  MPV_OPTS='--no-terminal';
  while { getopts mpbguchs:d opt } { case ${opt} {
    (m) MPV_OPTS='--no-video --msg-level=all=status';;
    (p) [[ -t 0 ]] && MPV_OPTS='--vo=tct --profile=sw-fast --vo-tct-256=yes --ytdl-format="best[height<=480]"';;
    (b) MPV_OPTS+=' -f best';;
    (g) yt_gen_links;;
    (u) yt_update_subs;;
    (c) yt_cat_subs;;
    (h) yt_die 'Usage: yt [-m (no-video)] [-p (terminal)] [-b (best)] [-d (download bestvideo+bestaudio/best)] [-g (gen-links)] [-u (update-cache)]';;
    #(s) ((# > OPTIND)) && ytf ${@[OPTIND+1,-1]}; return;;
    (s) ytf ${OPTARG};;
    (d) typeset dl;|
    (*) yt_get_sel;;
  }; };
  ((# == 0 && OPTIND == 1)) && yt_get_sel;
}
yt_main "$@";
