#!/bin/zsh
[[ -t 0 ]] || return 1;
# { which zsh && which pup && which curl && which uritool } &>/dev/null || return 2;
# ping -c 1 1.1.1.1 &>/dev/null || return 3;
emulate -LR zsh;
setopt pipe_fail extended_glob;
typeset query base cat t n; 
typeset -i results pages c q lr ls ll lc ld lt; 
typeset -a cats title size url category date hash;
typeset -ia seed leech;
n=$'\n'; 
t=$(mktemp);

for base (1337x.to 1337x.tw 1337x.st 1377x.one 1337x.gd x1337x.eu x1337x.se) {
  ping -c 1 ${base} &>/dev/null && { base=https://${base}; break };
} || return 3;

query="${${@}:-$(read -er "?${n}> ")}";
[[ ! ${query} =~ '^\s*$' ]] || return 4;
query=$(uritool query escape ${query});

cats=(Anime Apps Documentaries Games Movies Music Other TV XXX);
cat=${$(fzy -p 'Select category or search all: ' -l ${#cats} <<< ${(F)cats}):*cats};
[[ -z ${cat} ]] && query=/search/${query}/ || query=/category-search/${query}/${cat}/;

curl -sfH User-Agent: ${base}${query}1/ > ${t};
# ((${$(pup -f ${t} -n 'a[href^=/torrent/]'):-0} != 0)) || { printf ' No results.\n'; return 0 };

pages=${${$(pup -f ${t} '.last a attr{href}')%/}##*/};
if ((pages == 0)) {
   pages=1;
} elif ((pages > 4)) && [[ $(read -seq "?${n}${pages} pages, show all [y/*]?") == n ]] {
  read "q?${n}Input number of pages to display> ";
  ((q > 0 && q <= pages)) && pages=${q} || { printf 'Invalid selection; showing first 5 pages.\n'; pages=5 };
};

for q ( {1..${pages}} ) {
  title+=(${(f)"$(   pup -p -f ${t} 'td.name a text{}')"});
  seed+=(${(f)"$(    pup -p -f ${t} 'td.seeds text{}')"});
  leech+=(${(f)"$(   pup -p -f ${t} 'td.leeches text{}')"});
  size+=(${(f)"$(    pup -p -f ${t} 'td.size json{}' | jq -r '.[].text')"});
  url+=(${(f)"$(     pup -p -f ${t} 'td a[href^=/torrent/] attr{href}')"});
  category+=(${(f)"$(pup -p -f ${t} 'td.name .icon i attr{class}' | cut -d - -f 2-)"});
  date+=(${(f)"$(    pup -p -f ${t} 'td.coll-date text{}')"});
  curl -sfH User-Agent: ${base}${query}$((q + 1))/ > ${t};
};

results=${#title};
for q ( {1..${results}} ) {
  ((${(c)#title[q]}    > lt)) && lt=${(c)#title[q]};
  ((${(c)#category[q]} > lc)) && lc=${(c)#category[q]};
  ((${(c)#date[q]}     > ld)) && ld=${(c)#date[q]};
};

lr=${(c)#${results}};
ls=${(c)#${${(nO)seed}[1]}};
ll=${(c)#${${(nO)leech}[1]}};
# lt=$((COLUMNS - lr - 2 - 1 - 9 - 2 - 9 - 2 - ls - 1 - ll - 2 - 14));

while { true } {
  c=$(for q ( {1..${results}} ) {
    printf "%.${lr}d  %b%-${lt}.${lt}s %b%-${lc}.${lc}s  %b%9.9s  %b%.${ls}d%b/%b%.${ll}d  %b%${ld}.${ld}s\n" \
      $q \
      '\033[1m'    ${title[q]:- } \
      '\033[33;1m' ${category[q]:- } \
      '\033[34;1m' ${size[q]:- } \
      '\033[32;1m' ${seed[q]:- } \
      '\033[37;1m' \
      '\033[31;1m' ${leech[q]:- } \
      '\033[36;1m' ${date[q]:- };
  } | fzy -l $LINES | cut -f 1 -d ' ') || break;
  ((c > 0 && c <= ${results})) && {
    curl -sfH User-Agent: ${base}${(Q)url[c]} > ${t};
    hash+=($(pup -p -f ${t} 'a[href^=magnet] attr{href}'));
    [[ -n ${hash[-1]} ]] || hash[-1]=$(pup -p -f ${t} '.infohash-box span text{}');
  };
};

((${#hash} > 0)) && { qbittorrent ${(u)hash} &>/dev/null & disown };
rm ${t} &>/dev/null; return 0;
