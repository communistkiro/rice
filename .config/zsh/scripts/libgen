#!/bin/zsh
function menu () {
  typeset m t a;
  while getopts 'm:t:' a; do case $a in
  (m)
    [[ $OPTARG =~ '[0-7]' ]] && m='\033[0;3'${MATCH} || m='\033[0;37';
    [[ $OPTARG =~ 'i|I' ]]   && m="${m};7";
    [[ $OPTARG =~ 'b|B' ]]   && m="${m};1";
    m="${m}m";;
  (t)
    [[ $OPTARG =~ '[0-7]' ]] && t='\033[0;3'${MATCH} || t='\033[0;37';
    [[ $OPTARG =~ 'i|I' ]]   && t="${t};7";
    [[ $OPTARG =~ 'b|B' ]]   && t="${t};1";
    t="${t}m";;
  esac; done;
  for a in $@[OPTIND,-1]; do printf '%b%4s    %b%s%b\n' "${m:-\033[0m}" "${a%% *}" "${t:-\033[0m}" "${a#* }" '\033[0m'; done;
}

[[ -t 0 ]] || return 1;
# { which zsh && which pup && which curl && which wget && which pcre2grep && which uritool } &>/dev/null || return 2;
emulate -LR zsh;
setopt pipe_fail ksh_glob extended_glob;
typeset query baseurl tmp n z target;

n=$'\n'; tmp=$(mktemp);
query=${${@}:-$(read -er "?${n}> ")};
[[ ! ${query} =~ '^\s*$' ]] || return 4;

ping -c 1 libgen.is &>/dev/null && baseurl=http://libgen.is/ ||
ping -c 1 libgen.st &>/dev/null && baseurl=http://libgen.st/ ||
ping -c 1 libgen.rs &>/dev/null && baseurl=http://libgen.rs/ ||
return 3;

trap 'rm -f ${tmp} &>/dev/null; return 1' INT QUIT;

menu -m 4b -t 2b  'Search_where: ' \
  '1 LibGen (Sci-Tech)' \
  '2 Scientific articles' \
  '3 Fiction' \
  '4 Comics' \
  '5 Standards' \
  '6 Magazines';

case $(read -sek1 "?${n}") {
  (1)
    typeset -i results pages lr lt la le lp ls lf lP c q;
    typeset -a mirror title author md5 language edition publisher year length size format ext url;
    baseurl+=search.php\?view=detailed\&res=100;
    mirror=(
      http://library.lol/main/
      http://libgen.lc/ads.php\?md5=
      # http://b-ok.cc/md5/
      # https://libgen.pw/item?id=
      # http://bookfi.net/md5/
    );

   baseurl+=\&phrase=$((++q));
    menu -m 4b -t 2b 'Field_to_search: ' \
      '* any' \
      '1 title' \
      '2 authors' \
      '3 series' \
      '4 publisher' \
      '5 year' \
      '6 ISBN' \
      '7 language' \
      '8 md5' \
      '9 tags' \
      '0 extension' 
      case $(read -sek1 "?${n}> ") {
        (1) baseurl+=\&column=title;;
        (2) baseurl+=\&column=authors;;
        (3) baseurl+=\&column=series;;
        (4) baseurl+=\&column=publisher;;
        (5) baseurl+=\&column=year;;
        (6) baseurl+=\&column=isbn;;
        (7) baseurl+=\&column=year;;
        (8) baseurl+=\&column=md5;;
        (9) baseurl+=\&column=tags;;
        (0) baseurl+=\&column=extension;;
        (*) baseurl+=\&column=def;;
      };
      baseurl+=\&req=$(uritool query escape ${query});

    curl -sfH User-Agent: ${baseurl}\&open=0 > ${tmp};

    results=$(pup -p -f ${tmp} 'tbody tr td[align=left] text{}' | cut -d ' ' -f 1);
    ((results == 0)) && { read -sk1 "?${n}No results."; return 0 };
    ((results < 101)) && pages=1 || { pages=$((results / 100)); ((results % 100 == 0)) || pages=$((pages + 1)) };

    ((pages > 2)) && [[ $(read -seq "?${results} results over ${pages} pages. Show all [y/*]? ") == n ]] && {
      read -r "q?${n}Pages to show> ";
      ((q > 0 && q <= pages)) && {
        ((q == pages)) || {
          results=$((q * 100))
          pages=${q};
        };
      } || {
        read -sk1 "${n}Invalid selection.${n}Showing first 200 results only.";
        pages=2;
        results=200;
      };
    };

    for q ( {1..${pages}} ) {
      # SIMPLE VIEW
      # author+=(${(f)"$(pup -p -f ${tmp} 'tbody tr td:nth-child(2)')"});
      # md5+=(${${(f)"$(pup -f zz -p 'tbody tr td:nth-child(10) a attr{href}')"}##*/});
      # pup -p -f ${tmp} 'tbody tr td:nth-child(14) a json{}' | jq -r '.[].href'
      # pup -p -f ${tmp} 'tbody tr td:nth-child(14) a json{}' | jq -r '.[].style'
      # pup -p -f ${tmp} 'tbody tr td:nth-child(10--14)'         # a:not([style="color: grey"]) attr{href}
      # title edition isbn and publisher altogether in simple..
        # title+=(${(f)"$()"}); # isbn,
        # edition+=
        # publisher+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(4) a text{}')"}[2,-1]});
      # year+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(5) text{}')"}[2,-1]});
      # length+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(6) text{}')"}[2,-1]});
      # language+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(7) text{}')"}[2,-1]});
      # size+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(8) text{}')"}[2,-1]});
      # format+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(9) text{}')"}[2,-1]});

      # DETAILED VIEW
      author+=(${${(s.QQQQ.)"$(pup -p -f ${tmp} 'tbody td:nth-child(2) text{}' | perl -pe 'BEGIN {undef $/} s/\n,\n/,/g; s/\s*\nTitle\n(.+)\n(?:.+\n)+?\n{2}/QQQQ$1/g')"}[2,-1]});
      title+=(${${(f)"$(       pup -p -f ${tmp} 'tbody tr td[colspan=2] text{}')"}[2,-1]});
      md5+=(${${${(f)"$(       pup -p -f ${tmp} 'tbody tr td[colspan=2] b a attr{href}')"}##*=}});
      publisher+=(${${(f)"$(pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[4].children[1].text')"}[3,-2]});
      year+=(${${(f)"$(     pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[5].children[1].text')"}[3,-2]});
      edition+=(${${(f)"$(  pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[5].children[3].text')"}[3,-2]});
      length+=(${${(f)"$(   pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[6].children[3].text')"}[3,-2]//*([^0-9])(#b)(+([0-9]))*([^0-9]*)/${match[1]}});
      language+=(${${(f)"$( pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[6].children[1].text')"}[3,-2]});
      size+=(${${${(f)"$(   pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[9].children[1].text')"}[3,-2]%% \(*}});
      format+=(${${(f)"$(   pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[9].children[3].text')"}[3,-2]});
      # added=(${${(f)"$(     pup -f z -p 'tbody json{}' | jq -r '.[].children[9].children[3].text')"}[3,-2]});
      curl -sfH User-Agent: ${baseurl}\&sort=def\&sortmode=ASC\&page=$((++q)) > ${tmp};
    };

    lr=${(c)#results};
    for q ( {1..${results}} ) {
      ((${(c)#title[q]}     > lt)) && lt=${(c)#title[q]};
      ((${(c)#edition[q]}   > le)) && le=${(c)#edition[q]};
      ((${(c)#publisher[q]} > lp)) && lp=${(c)#publisher[q]};
      ((${(c)#author[q]}    > la)) && la=${(c)#author[q]};
      ((${(c)#length[q]}    > ll)) && ll=${(c)#length[q]};
      ((${(c)#size[q]}      > ls)) && ls=${(c)#size[q]};
      ((${(c)#format[q]}    > lf)) && lf=${(c)#format[q]};
      ((${(c)#language[q]}  > lL)) && lL=${(c)#language[q]};
    };
    # lt=$((COLUMNS - lr - 1 - 1 - le - 1 - lp - 1 - 4 - 1 - lL - 1 - la - 1 - ll - 1 - ls - 1 - lf));
    lP=$((lr + 1 + lt + 1 + le + 1 + lp + 1 + 4 + 1 + lL + 1 + la + 1 + ll + 1 + ls + 1 + lf));
    ((lP % COLUMNS == 0)) && lP=$((lP / COLUMNS)) || lP=$((lP / COLUMNS + 1));

    while { true } {
      c=$(for q ( {1..${results}} ) {
        printf "%.${lr}d %b%-${lt}.${lt}s %-${le}.${le}s %b%-${lp}.${lp}s %b%-4.4s %b%-${la}.${la}s %b%${lL}.${lL}s %b%${ll}.${ll}s %b%${ls}.${ls}s %b%-${lf}.${lf}s\n" \
          $q \
          '\033[37;1m' ${title[q]:- } \
                       ${edition[q]:/null/ } \
          '\033[36;1m' ${publisher[q]:/null/ } \
          '\033[35;1m' ${year[q]:/null/ } \
          '\033[33;1m' ${author[q]:- } \
          '\033[30;1m' ${language[q]:/null/ } \
          '\033[31;1m' ${length[q]:/null/ } \
          '\033[34;1m' ${size[q]:/null/ } \
          '\033[32;1m' ${format[q]:/null/ };
      } | fzf -i +m --reverse --ansi --preview-window=down:${lP}:wrap:noborder --preview='printf "%s\n" {}' | cut -d ' ' -f 1) || break;
      ((c > 0 && c <= results)) && {
        while { true } {
          clear;
          case $(nl -n ln <<< ${(F)mirror} | fzf -i +m --reverse --tiebreak=begin | cut -d ' ' -f 1) {
            (1) url+=($(curl -sfH User-Agent: ${mirror[1]}${md5[c]} | pup -p 'div#download a attr{href}' | nl -n ln | fzf -i +m --reverse --tiebreak=begin | cut -f 2)) && ext+=(${(L)format[c]}) || read -sk1 "?${n}Try another mirror.";;
            (2) url+=($(curl -sfH User-Agent: ${mirror[2]}${md5[c]} | pup -p ':parent-of(h2) attr{href}'))       && ext+=(${(L)format[c]}) || read -sk1 "?${n}Try another mirror.";;
            (3) read -sk1 "?${n}FIXME";; # url+=($(curl -sfLH User-Agent: ${mirror[3]}${md5[c]} | pup -p '...'))
            (4) read -sk1 "?${n}FIXME";; # url+=($(curl -sfLH User-Agent: ${mirror[4]}${md5[c]} | pup -p '...'))
            (5) read -sk1 "?${n}FIXME";; # url+=($(curl -sfLH User-Agent: ${mirror[5]}${md5[c]} | pup -p '...'))
            (*) break;;
          };
        };
      };
    };

    printf '%s\n' 'All URLs:' ${url};
    q=0;
    for n ( ${url} ) {
      [[ ${n} =~ "\.${ext[++q]}$" ]] && {
        [[ ${n} =~ '\?filename=' ]] && {
          target=$(uritool query unescape ${n#*=});
          wget -nc -O ~/Downloads/${target} ${n};
        } || wget -nc -P ~/Downloads/ ${n};
      } || {
        wget -O ~/Downloads/$(tr -cd '[:alnum:]' < /dev/urandom | head -c 8).${ext[q]} ${n};
      };
    };
  ;;
  (2)
    baseurl+=scimag/;
    baseurl+=\?q=$(uritool query escape ${query});
    typeset -a mirror title author journal volume size doi url;
    typeset -i pages lr lt la lj lv ls lP q c;

    curl -sfH User-Agent: ${baseurl} > ${tmp};
    [[ $(pup -p -f ${tmp} 'html body p:nth-last-child(2) text{}') == 'No articles were found.' ]] && { printf '%s\n' 'No articles were found.'; return 0 };
    pages=$(pup -f ${tmp} '.page_selector text{}' | head -n 1 | cut -d ' ' -f 4);
    # mirror=(
    #   https://sci-hub.do/
    #   http://libgen.lc/scimag/ads.php\?doi=
    #   http://booksc.xyz/s/\?q=
    # );
    mirror=($(pcre2grep -o1 '^(.+[=/])(\d{2}\.\d+.+|\2)$' <<< ${(F)${(f)"$(pup -p -f ${tmp} 'tbody tr td ul.record_mirrors a attr{href}')"}[1,3]}));

    for q ( {1..${pages}} ) {
      doi+=(${${(f)"$(  pup -p -f ${tmp} 'tbody tr td:nth-child(4) a attr{href}')"}#*=});
      title+=(${${(ps.</a>.)"$(pup -p -f ${tmp} 'tbody tr td:nth-child(2) p:first-child a' | perl -pe 'BEGIN {undef $/} s/^<a href.+\n//m; s/(\S)\n\s*/$1/g; s/<\/?em>//g')"}});
      author+=(${(f)"$( pup -p -f ${tmp} 'tbody tr td:nth-child(1) text{}')"});
      journal+=(${(f)"$(pup -p -f ${tmp} 'tbody tr td:nth-child(3) p:first-child text{}')"});
      volume+=(${(f)"$( pup -p -f ${tmp} 'tbody tr td:nth-child(3) p:last-child  text{}')"});
      size+=(${(ps.\[edit\].)"$(pup -p -f ${tmp} 'tbody tr td:nth-child(4) text{}' | tr -d '\n')"});
      curl -sfH User-Agent: ${baseurl}\&page=$((++q)) > ${tmp};
    };
    
    results=${#doi};
    lr=${(c)#results};
    for q ( {1..${results}} ) {
      ((${(c)#title[q]}   > lt)) && lt=${(c)#title[q]};
      ((${(c)#author[q]}  > la)) && la=${(c)#author[q]};
      ((${(c)#journal[q]} > lj)) && lj=${(c)#journal[q]};
      ((${(c)#volume[q]}  > lv)) && lv=${(c)#volume[q]};
      ((${(c)#size[q]}    > ls)) && ls=${(c)#size[q]};
    };
    # lt=$((COLUMNS - lr - 1 - 1 - la - 1 - lj - 1 - lv - 1 - ls));
    lP=$((lr + 1 + lt + 1 + la + 1 + lj + 1 + lv + 1 + ls));
    ((lP % COLUMNS == 0)) && lP=$((lP / COLUMNS)) || lP=$((lP / COLUMNS + 1));    

   while { true } {
      c=$(for q ( {1..${results}} ) {
        printf "%.${lr}d %b%-${lt}.${lt}s %b%-${la}.${la}s %b%-${lj}.${lj}s %b%-${lv}.${lv}s %b%${ls}.${ls}s\n" \
          $q \
          '\033[37;1m' ${title[q]:- } \
          '\033[34;1m' ${author[q]:- } \
          '\033[33;1m' ${journal[q]:- } \
          '\033[33;1m' ${volume[q]:- } \
          '\033[32;1m' ${size[q]:- };
      } | fzf -i +m --reverse --ansi --preview-window=down:${lP}:wrap:noborder --preview='printf "%s\n" {}' | cut -d ' ' -f 1) || break;

      ((c > 0 && c <= results)) && {
        while { true } {
          clear;
          case $(nl -n ln <<< ${(F)mirror} | fzf -i +m --reverse --tiebreak=begin | cut -d ' ' -f 1) {
            (1) url+=($(curl -sfH User-Agent: ${mirror[1]}${doi[c]} | pup -p 'div ul li a attr{href}' | pcre2grep -o1 '(http.+)\?download=true')) || read -sk1 "?${n}Try another mirror.";;
            (2) url+=($(curl -sfH User-Agent: ${mirror[2]}${doi[c]} | pup -p 'a:parent-of(h2) attr{href}')) || read -sk1 "?${n}Try another mirror.";;
            (3) url+=(https://booksc.xyz$(curl -sfH User-Agent: ${mirror[3]}${doi[c]} | pup -p 'a.dlButton attr{href}')) || read -sk1 "?${n}Try another mirror.";;
            (*) break;;
          };
        };
      };
    };

    printf '%s\n' 'All URLs:' ${url};
    for n ( ${url} ) {
      [[ ${n} =~ '\.pdf$' ]] && {
        target=$(uritool query unescape ${n##*/});
        wget -nc -O ~/Downloads/${target} ${n};
      } || {
        wget -O ~/Downloads/$(tr -cd '[:alnum:]' < /dev/urandom | head -c 8).pdf ${n};
      };
    };
  ;;
  (3)
    typeset -i results pages lr lt la ls ll lP c q;
    typeset -a mirror title author md5 language series sizeformat formats ext url langs format lang;

    formats=(epub mobi azw azw3 fb2 pdf rtf txt);
    baseurl+=fiction/;
    langs=(${(f)"$(curl -sfH User-Agent: ${baseurl} | pup -p 'select[name=language] option attr{value}')"});
    baseurl+=\?q=$(uritool query escape ${query});
    mirror=(
      http://library.lol/fiction/
      http://libgen.lc/foreignfiction/ads.php\?md5=
      http://b-ok.cc/md5/
    );

    menu -m 4b -t 2b 'Field_to_search: ' \
      '* any' \
      '1 title' \
      '2 authors' \
      '3 series';
    case $(read -sek1 "?${n}") {
      (1) baseurl+=\&criteria=title;;
      (2) baseurl+=\&criteria=authors;;
      (3) baseurl+=\&criteria=series;;
      (*) baseurl+=\&criteria=;;
    };

    [[ $(read -seq "?${n}Query uses wildcards [y/*]?> ") == y ]] && baseurl+=\&wildcard=1;

    lang=($(fzy -l $LINES -p 'Language?> ' <<< ${(F)langs}));
    lang=${lang:*langs};
    baseurl+=\&language=${lang};

    format=($(fzy -l $LINES -p 'Format?> ' <<< ${(F)formats}));
    format=${format:*formats};
    baseurl+=\&format=${format};

    curl -sfLH User-Agent: ${baseurl} > ${tmp};

    [[ $(pup -f ${tmp} 'p text{}' | tail -n 1) == 'No files were found.' ]] && { read -sk1 "?${n}No results."; return 0 };
    pages=$(pup -f ${tmp} '.page_selector text{}' | head -n 1 | cut -d ' ' -f 4);
    results=${${"$(pup -f ${tmp} '.catalog_paginator [style=float:left] text{}' | head -n 1)"%% files found}#* }; # retarded: ' '  U+00A0  160    c2 a0       &nbsp;     NO-BREAK SPACE (Space_Separator)
    ((results == 0)) && { read -sk1 "?${n}No results."; return 0 };

    ((pages > 4)) && [[ $(read -seq "?${results} results over ${pages} pages. Show all [y/*]? ") == n ]] && {
      read -r "q?${n}Pages to show> ";
      ((q > 0 && q <= pages)) && {
        ((p == pages)) || {
          results=$((q * 25))
          pages=${q};
        };
      } || {
        read -sk1 "${n}Invalid selection.${n}Showing first 100 results only.";
        pages=4;
        results=100;
      };
    };

    for q ( {1..${pages}} ) {
      author+=(${(f)"$(    pup -p -f ${tmp} 'tbody td:nth-child(1) text{}' | perl -pe 'BEGIN {undef $/} s/(\w.+)\n(\w.+)/$2 $1/g; s/(\S)\n(\S)/$1 $2/g; s/\s{2,}/\n/g; s/(.+?), (.+)/$2 $1/g')"});
      md5+=(${${(f)"$(     pup -p -f ${tmp} 'tbody td:nth-child(6) li:first-of-type a attr{href}')"}##*/});
      title+=(${(f)"$(     pup -p -f ${tmp} 'tbody td:nth-child(3) text{}')"});
      series+=(${(f)"$(    pup -p -f ${tmp} 'tbody td:nth-child(2) json{}' | jq -r '.[].text')"});
      sizeformat+=(${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(5) text{}')"});
      # [[ -n ${lang} ]] ||
      language+=(${(f)"$(  pup -p -f ${tmp} 'tbody td:nth-child(4) text{}')"});
      curl -sfH User-Agent: ${baseurl}\&page=$((++q)) > ${tmp};
    };

    lr=${(c)#results};
    for q ( {1..${results}} ) {
      ((${(c)#title[q]}    > lt)) && lt=${(c)#title[q]};
      ((${(c)#series[q]}   > ls)) && ls=${(c)#series[q]};
      ((${(c)#author[q]}   > la)) && la=${(c)#author[q]};
      # [[ -n ${lang} ]] ||
      ((${(c)#language[q]} > ll)) && ll=${(c)#language[q]};
    };
    # lt=$((COLUMNS - lr - 1 - 1 - ls - 1 - la - 1 - ll - 10 - 6));
    lP=$((lr + 1 + lt + 1 + ls + 1 + la + 1 + ll + 10 + 6));
    ((lP % COLUMNS == 0)) && lP=$((lP / COLUMNS)) || lP=$((lP / COLUMNS + 1));

    while { true } {
      c=$(for q ( {1..${results}} ) {
        printf "%.${lr}d %b%-${lt}.${lt}s %b%-${ls}.${ls}s %b%-${la}.${la}s %b%${ll}.${ll}s%b%10.10s%b%6.6s\n" \
          $q \
          '\033[37;1m' ${title[q]:- } \
          '\033[36;1m' ${series[q]:/null/ } \
          '\033[33;1m' ${author[q]:- } \
          '\033[31;1m' ${language[q]:- } \
          '\033[34;1m' ${${sizeformat[q]#* / }:- } \
          '\033[32;1m' ${${sizeformat[q]% / *}:- };
      } | fzf -i +m --reverse --ansi --preview-window=down:${lP}:wrap:noborder --preview='printf "%s\n" {}' | cut -d ' ' -f 1) || break;

      ((c > 0 && c <= results)) && {
        while { true } {
          clear;
          case $(nl -n ln <<< ${(F)mirror} | fzf -i +m --reverse --tiebreak=begin | cut -d ' ' -f 1) {
            (1) url+=($(curl -sfH User-Agent: ${mirror[1]}${md5[c]} | pup -p 'div#download a attr{href}' | nl -n ln | fzf -i +m --reverse --tiebreak=begin | cut -f 2)) && ext+=(${(L)sizeformat[c]% / *}) || read -sk1 "?${n}Try another mirror.";;
            (2) url+=($(curl -sfH User-Agent: ${mirror[2]}${md5[c]} | pup -p ':parent-of(h2) attr{href}'))       && ext+=(${(L)sizeformat[c]% / *}) || read -sk1 "?${n}Try another mirror.";;
            (3) read -sk1 "?${n}FIXME";; # url+=($(curl -sfLH User-Agent: ${mirror[3]}${md5[c]} | pup -p '')); ext+=(${(L)sizeformat[c]% / *});;
            (*) break;;
          };
        };
      };
    };

    printf '%s\n' 'All URLs:' ${url};
    q=0;
    for n ( ${url} ) {
      [[ ${n} =~ "\.${ext[++q]}$" ]] && {
        [[ ${n} =~ '\?filename=' ]] && target=${n#*=} || target=${n##*/};
        target=$(uritool query unescape ${target});
        wget -nc -O ~/Downloads/${target} ${n};
      } || {
        wget -O ~/Downloads/$(tr -cd '[:alnum:]' < /dev/urandom | head -c 8).${ext[q]} ${n};
      };
    };
  ;;
  (4)
    typeset -i results pages lr lt li lv lp ld lP q;
    typeset -a title issue volume publisher language date issuehash serieshash url file;
    baseurl=libgen.lc/comics/index.php\?s=$(uritool query escape ${query})\&res=100\&sorted=1;
    [[ $(read -seq "?${n}Query uses wildcards [y/*]?> ") == y ]] && baseurl+=\&mask=1; printf '\n';

    menu -m 4b -t 2b 'Search_for: ' \
      '* all FIXME' \
      '1 series' \
      '2 issues' \
      '3 files FIXME';
    case $(read -sek1 "?${n}") {
      (1) baseurl+=\&show=1;;
      (2) baseurl+=\&show=2;;
      (3) read -sk1 "?${n}FIXME"; return 1;; # baseurl+=\&show=3;;
      (*) read -sk1 "?${n}FIXME"; return 1;; # baseurl+=\&show=0;;
    };

    curl -sfH User-Agent: ${baseurl} > ${tmp};
    results=$(pup -p -f ${tmp} 'font[size=1]:contains("results") text{}' | pcre2grep -o1 'Found.*?(\d+).*results');
    ((results == 0)) && { printf 'No results.\n'; return 0 };
    ((results < 101)) && pages=1 || { pages=$((results / 100)); ((results % 100 == 0)) || pages=$((pages + 1)) };

    ((pages > 2)) && [[ $(read -seq "?${results} results over ${pages} pages. Show all [y/*]? ") == n ]] && {
      read -r "q?${n}Pages to show> ";
      ((q > 0 && q <= pages)) && {
        ((q == pages)) || {
          results=$((q * 100))
          pages=${q};
        };
      } || {
        read -sk1 "${n}Invalid selection.${n}Showing first 200 results only.";
        pages=2;
        results=200;
      };
    };

    case ${(M)baseurl%?} {
      (2)
        for p ( {1..${pages}} ) {
          issuehash+=(${(f)"$(             pup -p -f ${tmp} 'tbody a[href^=seriestable.php?issue_hash]  attr{href}')"});
          serieshash+=(${(f)"$(            pup -p -f ${tmp} 'tbody a[href^=seriestable.php?series_hash] attr{href}')"});
          title+=(${(f)"$(                 pup -p -f ${tmp} 'tbody a[href^=seriestable.php?series_hash] text{}')"});
          issue+=(${${(s.Issue: .)"$(      pup -p -f ${tmp} 'tbody td:contains("Issue: ") text{}'     | tr -d '\n')"}%Volume:*});
          volume+=(${${${(s.Volume: .)"$(  pup -p -f ${tmp} 'tbody td:contains("Volume: ") text{}'    | tr -d '\n')"}%% *Issue:*}});
          date+=(${(s.Year: .)"$(          pup -p -f ${tmp} 'tbody :contains("Year: ") text{}'        | tr -d '\n')"});
          language+=(${(s.Language: .)"$(  pup -p -f ${tmp} 'tbody td:contains("Language: ") text{}'  | tr -d '\n')"});
          publisher+=(${(s.Publisher: .)"$(pup -p -f ${tmp} 'tbody td:contains("Publisher: ") text{}' | tr -d '\n')"});
          curl -sfH User-Agent: ${baseurl}\&page=$((++q)) > ${tmp};
        };
        ;;
      (1)
        for q ( {1..${pages}} ) {
          serieshash+=(${(f)"$(            pup -p -f ${tmp} 'tbody a[href^=seriestable.php?series_hash] attr{href}')"});
          title+=(${(f)"$(                 pup -p -f ${tmp} 'tbody a[href^=seriestable.php?series_hash] text{}')"});
          issue+=(${(s.Issues: .)"$(       pup -p -f ${tmp} 'tbody :contains("Issues: ") text{}'      | tr -d '\n')"});
          volume+=(${(s.Volume: .)"$(      pup -p -f ${tmp} 'tbody :contains("Volume: ") text{}'      | tr -d '\n')"});
          date+=(${(s,Publ. Period: ,)"$(  pup -p -f ${tmp} 'tbody :contains("Publ. Period: ") text{}'| tr -d '\n')"});
          language+=(${(s.Language: .)"$(  pup -p -f ${tmp} 'tbody :contains("Language: ") text{}'    | tr -d '\n')"});
          publisher+=(${(s.Publisher: .)"$(pup -p -f ${tmp} 'tbody :contains("Publisher: ") text{}'   | tr -d '\n')"});
          curl -sfH User-Agent: ${baseurl}\&page=$((++q)) > ${tmp};
        };
        ;;
    };

    lr=${(c)#results};
    for q ( {1..${results}} ) {
      ((${(c)#title[q]}     > lt)) && lt=${(c)#title[q]};
      ((${(c)#issue[q]}     > li)) && li=${(c)#issue[q]};
      ((${(c)#volume[q]}    > lv)) && lv=${(c)#volume[q]};
      ((${(c)#publisher[q]} > lp)) && lp=${(c)#publisher[q]};
      ((${(c)#date[q]}      > ld)) && ld=${(c)#date[q]};
    };
    # lt=$((COLUMNS - lr - 1 - 1 - lv - 1 - li - 1 - lp - 1 - 2 - 1 - ld));
    lP=$((lr + 1 + lt + 1 + lv + 1 + li + 1 + lp + 1 + 2 + 1 + ld));
    ((lP % COLUMNS == 0)) && lP=$((lP / COLUMNS)) || lP=$((lP / COLUMNS + 1));

    while { true } {
      c=$(for q ( {1..${results}} ) {
        printf "%.${lr}d %b%-${lt}.${lt}s %b%-${lv}.${lv}s %b%-${li}.${li}s %b%-${lp}.${lp}s %b%2.2s %b%-${ld}.${ld}s\n" \
          $q \
          '\033[37;1m' ${title[q]:- } \
          '\033[34;1m' ${volume[q]:- } \
          '\033[32;1m' ${issue[q]:- } \
          '\033[33;1m' ${publisher[q]:- } \
          '\033[35;1m' ${(U)language[q]:- } \
          '\033[31;1m' ${date[q]:- };
      } | fzf -i +m --reverse --ansi --preview-window=down:${lP}:wrap:noborder --preview='printf "%s\n" {}' | cut -d ' ' -f 1) || break;

      ((c > 0 && c <= results)) && {
        if [[ ${(M)baseurl%?} == 1 ]] || { [[ ${(M)baseurl%?} == 2 ]] && [[ $(read -seq "?${n}Download entire series [y/*]? ") == y ]] } {
          curl -sfLH User-Agent: http://libgen.lc/comics/${serieshash[c]} > ${tmp} || break;
          q=0;
          for n ( ${(f)"$(pup -p -f ${tmp} 'tbody tr tr:first-child a[href^=get] attr{href}')"} ) {
            url+=(http://libgen.lc/comics/${n});
            ((++q));
          };
          typeset -Z ${(c)#${q}}; q=0;
          for n ( ${${(f)"$(pup -p -f ${tmp} 'tbody tr tr:first-child a[href^=get] text{}')"}%/*} ) {
            file+=("${title[c]}-${volume[c]}-${issue[c]}.$((++q)).${n}");
          };
        } elif [[ ${(M)baseurl%?} == 2 ]] {
          curl -sfH User-Agent: http://libgen.lc/comics/${issuehash[c]} > ${tmp} || break;
          file+=("${title[c]}-${volume[c]}-${issue[c]}.${${(f)"$(pup -f ${tmp} 'a[href^=get] text{}')"}[1]%/*}");
          url+=(http://libgen.lc/comics/${${(f)"$(pup -f ${tmp} 'a[href^=get] attr{href}')"}[1]});
        };
      };
    };

    printf '%s\n' 'All URLs:' ${url};
    q=0;
    for n ( ${url} ) {
      target=$(uritool query unescape ${file[++q]});
      wget -nc -O ~/Downloads/${target} ${n};
    };
  ;;
  (5)
    typeset -i pages results lr lt ls lf lS lp ln ll lP q c;
    typeset -a title format length language pubdate size url;
    baseurl=http://libgen.lc/standarts/index.php\?s=$(uritool query escape ${query});

    curl -sfLH User-Agent: ${baseurl} > ${tmp};
    results=$(pup -p -f ${tmp} | pcre2grep -o1 'Found.*?(\d+).*results');
    ((results == 0)) && { printf 'No results.\n'; return 0 };
    ((results < 26)) && pages=1 || { pages=$((results / 25)); ((results % 25 == 0)) || pages=$((pages + 1)) };

    ((pages > 4)) && [[ $(read -seq "?${results} results over ${pages} pages. Show all [y/*]? ") == n ]] && {
      read -r "q?${n}Pages to show> ";
      ((q > 0 && q <= pages)) && {
        ((q == pages)) || {
          results=$((q * 25))
          pages=${q};
        };
      } || {
        read -sk1 "${n}Invalid selection.${n}Showing first 100 results only.";
        pages=4;
        ((results >= 100 )) && results=100;
      };
    };

    for q ( {1..${pages}} ) {
      number+=(${(f)"$(  pup -p -f ${tmp} 'tbody tr td[width=200] b text{}')"});
      md5+=(${(f)"$(     pup -p -f ${tmp} 'tbody td:nth-child(2) td:nth-child(1) a text{}')"});
      format+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(2) td:nth-child(3) text{}')"}//Extension: (#b)(*);/${match[1]}});
      size+=($(numfmt --to=iec <<< ${(F)${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(2) td:nth-child(2) text{}')"}//Filesize: (#b)(+([0-9]));/${match[1]}}));
      Status+=(${(f)"$(  pup -p -f ${tmp} 'tbody td:nth-child(3) text{}' | pcre2grep -M -o1 'Status:\n(.*)')"});
      length+=(${(f)"$(  pup -p -f ${tmp} 'tbody td:nth-child(3) text{}' | pcre2grep -M -o1 'Pages:\n(.*)')"});
      language+=(${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(3) text{}' | pcre2grep -M -o1 'Language:\n(.*)')"});
      title+=(${(f)"$(   pup -p -f ${tmp} 'tbody td[width=400] text{}'   | pcre2grep -M -o1 '(.*)\nMD5:')"});
      pubdate+=(${(f)"$( pup -p -f ${tmp} 'tbody td:nth-child(1) tr:nth-child(3) td:nth-child(2) text{}')"});
      curl -sfH User-Agent: ${baseurl}\&page=$((++q)) > ${tmp};
    };

    lr=${(c)#results};
    for q ( {1..${results}} ) {
      ((${(c)#title[q]}   > lt)) && lt=${(c)#title[q]};
      ((${(c)#number[q]}  > ln)) && ln=${(c)#number[q]};
      ((${(c)#pubdate[q]} > lp)) && lp=${(c)#pubdate[q]};
      ((${(c)#Status[q]}  > lS)) && lS=${(c)#Status[q]};
      ((${(c)#length[q]}  > ll)) && ll=${(c)#length[q]};
      ((${(c)#size[q]}    > ls)) && ls=${(c)#size[q]};
      ((${(c)#format[q]}  > lf)) && lf=${(c)#format[q]};
    };
    # lt=$((COLUMNS - lr - 1 - 1 - ln - 1 - lp - 1 - lS - 1 - ll - 1 - ls - 1 - lf));
    lP=$((lr + 1 + lt + 1 + ln + 1 + lp + 1 + lS + 1 + ll + 1 + ls + 1 + lf));
    ((lP % COLUMNS == 0)) && lP=$((lP / COLUMNS)) || lP=$((lP / COLUMNS + 1));

    while { true } {
      c=$(for q ( {1..${results}} ) {
        printf "%.${lr}d %b%-${lt}.${lt}s %b%-${ln}.${ln}s %b%-${lp}.${lp}s %b%${lS}.${lS}s %b%${ll}.${ll}s %b%${ls}.${ls}s %b%${lf}.${lf}s\n" \
          $q \
          '\033[37;1m' ${title[q]:- } \
          '\033[34;1m' ${number[q]:- } \
          '\033[35;1m' ${pubdate[q]:- } \
          '\033[36;1m' ${Status[q]:- } \
          '\033[30;1m' ${length[q]:- } \
          '\033[33;1m' ${size[q]:- } \
          '\033[31;1m' ${format[q]:- };
      } | fzf -i +m --reverse --ansi --preview-window=down:${lP}:wrap:noborder --preview='printf "%s\n" {}' | cut -d ' ' -f 1) || break;

      ((c > 0 && c <= results)) && { url+=($(curl -sfH User-Agent: http://libgen.lc/standarts/get.php\?md5=${md5[c]})); ext+=(${(L)format[c]}) }
    };

    printf '%s\n' 'All URLs:' ${url};
    q=0;
    for n ( ${url} ) {
      wget -O ~/Downloads/$(tr -cd '[:alnum:]' < /dev/urandom | head -c 8).${ext[++q]:-pdf} ${n};
    };
  ;;
  (6)
    baseurl=http://magzdb.org/\?q=$(uritool query escape ${query});
    return 0;
  ;;
  (*) return 1;;
};

rm -f ${tmp} &>/dev/null

# FULL TEXT SEARCH
# https://b-ok.cc/fulltext/
