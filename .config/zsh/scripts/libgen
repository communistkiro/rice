#!/bin/zsh
function menu () {
  typeset m t a;
  while getopts 'm:t:' a; do case $a in
  (m)
    [[ $OPTARG =~ '[0-7]' ]] && m='\033[0;3'${MATCH} || m='\033[0;37';
    [[ $OPTARG =~ 'i|I' ]]   && m="${m};7";
    [[ $OPTARG =~ 'b|B' ]]   && m="${m};1";
    m="${m}m";;
  (t)
    [[ $OPTARG =~ '[0-7]' ]] && t='\033[0;3'${MATCH} || t='\033[0;37';
    [[ $OPTARG =~ 'i|I' ]]   && t="${t};7";
    [[ $OPTARG =~ 'b|B' ]]   && t="${t};1";
    t="${t}m";;
  esac; done;
  for a in $@[OPTIND,-1]; do printf '%b%4s    %b%s%b\n' "${m:-\033[0m}" "${a%% *}" "${t:-\033[0m}" "${a#* }" '\033[0m'; done;
}

[[ -t 0 ]] || return 1;
# { which zsh && which pup && which curl && which wget && which pcre2grep } &>/dev/null || return 2;
emulate -LR zsh;
setopt pipe_fail ksh_glob extended_glob;
typeset query baseurl tmp n;

n=$'\n'; tmp=$(mktemp);
query=${${@}:-$(read -er "?${n}> ")};
[[ ! ${query} =~ '^\s*$' ]] || return 4;

{ ping -c 1 libgen.rs &>/dev/null } && { baseurl=http://libgen.is/ } ||
{ ping -c 1 libgen.is &>/dev/null } && { baseurl=http://libgen.rs/ } ||
{ ping -c 1 libgen.st &>/dev/null } && { baseurl=http://libgen.st/ } ||
{ return 3 };

trap 'rm -f ${tmp} &>/dev/null; return 1' INT QUIT;

menu -m 4b -t 2b  'Search_where: ' \
  '1 LibGen (Sci-Tech)' \
  '2 Scientific articles' \
  '3 Fiction' \
  '4 Comics' \
  '5 Standards' \
  '6 Magazines';

case $(read -sek1 "?${n}") {
  (1)
    typeset -i results pages lr lt la le lp ls lf p c q;
    typeset -a mirror title author md5 language edition publisher year length size format ext url;
    baseurl+=search.php\?view=detailed\&res=100;
    mirror=(
      http://library.lol/main/
      http://libgen.lc/ads.php\?md5=
      http://b-ok.cc/md5/
      # https://libgen.pw/item?id= 9053
      http://bookfi.net/md5/
    );

   baseurl+=\&phrase=$((++q));
    menu -m 4b -t 2b 'Field_to_search: ' \
      '* any' \
      '1 title' \
      '2 authors' \
      '3 series' \
      '4 publisher' \
      '5 year' \
      '6 ISBN' \
      '7 language' \
      '8 md5' \
      '9 tags' \
      '0 extension' 
    # while { true } { # FIXME MULTIPHRASE QUERY?
      case $(read -sek1 "?${n}> ") {
      # case $(printf '%s\n' 'd any' '1 title' '2 authors' '3 series' '4 publisher' '5 year' '6 ISBN' '7 language' '8 md5' '9 tags' '0 extension' | fzy -l 11 | cut -d ' ' -f 1) {
        # ([0-9d]) baseurl+=\&phrase=$((++q));|
        (1) baseurl+=\&column=title;;
        (2) baseurl+=\&column=authors;;
        (3) baseurl+=\&column=series;;
        (4) baseurl+=\&column=publisher;;
        (5) baseurl+=\&column=year;;
        (6) baseurl+=\&column=isbn;;
        (7) baseurl+=\&column=year;;
        (8) baseurl+=\&column=md5;;
        (9) baseurl+=\&column=tags;;
        (0) baseurl+=\&column=extension;;
        # (d) baseurl+=\&column=def;;
        # (*) break;;
        (*) baseurl+=\&column=def;;
      };
      baseurl+=\&req=${query// /+};
      # read -r "?${n}query> "
    # };

    curl -sfLH User-Agent: ${baseurl}\&open=0 > ${tmp};

    results=$(pup -p -f ${tmp} 'tbody tr td[align=left] text{}' | cut -d ' ' -f 1);
    ((results == 0)) && { printf 'No results.\n'; return 1 };
    ((results < 101)) && { pages=1; ((results < 3)) && results=3 } || { pages=$((results / 100)); ((results % 100 == 0)) || pages=$((pages + 1)) };

    ((pages > 2)) && {
      printf '%s\n' "${results} results over ${pages} pages.";
      read -r "p?${n}Pages to show> ";
      ((p > 0 && p <= pages)) && {
        ((p == pages)) || {
          results=$((p * 100))
          pages=${p};
        };
      } || {
        printf '%s\n' 'Invalid selection.' 'Showing first 200 results only.';
        pages=2;
        results=200;
      };
    };

    for p ( {1..${pages}} ) {
      # SIMPLE VIEW
      # author+=(${(f)"$(pup -p -f ${tmp} 'tbody tr td:nth-child(2)')"});
      # md5+=(${${(f)"$(pup -f zz -p 'tbody tr td:nth-child(10) a attr{href}')"}##*/});
      # pup -p -f ${tmp} 'tbody tr td:nth-child(14) a json{}' | jq -r '.[].href'
      # pup -p -f ${tmp} 'tbody tr td:nth-child(14) a json{}' | jq -r '.[].style'
      # pup -p -f ${tmp} 'tbody tr td:nth-child(10--14)'         # a:not([style="color: grey"]) attr{href}
      # title edition isbn and publisher altogether in simple..
        # title+=(${(f)"$()"}); # isbn,
        # edition+=
        # publisher+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(4) a text{}')"}[2,-1]});
      # year+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(5) text{}')"}[2,-1]});
      # length+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(6) text{}')"}[2,-1]});
      # language+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(7) text{}')"}[2,-1]});
      # size+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(8) text{}')"}[2,-1]});
      # format+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(9) text{}')"}[2,-1]});

      # DETAILED VIEW
      # author+=(${(f)"$(pup -p -f ${tmp} 'tbody tr td[colspan=3] text{}' | perl -pe 'BEGIN {undef $/} s/\n,\n/,/mg; s/\n+/\n/mg')"});
      author+=(${${(s.QQQQ.)"$(pup -p -f ${tmp} 'tbody td:nth-child(2) text{}' | perl -pe 'BEGIN {undef $/} s/\n,\n/,/mg; s/\n+Title\n(.+)\n(?:.+\n)+?\n{2}/QQQQ$1/mg')"}[2,-1]});
      title+=(${${(f)"$(       pup -p -f ${tmp} 'tbody tr td[colspan=2] text{}')"}[2,-1]});
      md5+=(${${${(f)"$(       pup -p -f ${tmp} 'tbody tr td[colspan=2] b a attr{href}')"}##*=}});
      publisher+=(${${(f)"$(pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[4].children[1].text')"}[3,-2]});
      year+=(${${(f)"$(     pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[5].children[1].text')"}[3,-2]});
      edition+=(${${(f)"$(  pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[5].children[3].text')"}[3,-2]});
      length+=(${${(f)"$(   pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[6].children[3].text')"}[3,-2]//*([^0-9])(#b)(+([0-9]))*([^0-9]*)/${match[1]}});
      language+=(${${(f)"$( pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[6].children[1].text')"}[3,-2]});
      size+=(${${${(f)"$(   pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[9].children[1].text')"}[3,-2]%% \(*}});
      format+=(${${(f)"$(   pup -p -f ${tmp} 'tbody json{}' | jq -r '.[].children[9].children[3].text')"}[3,-2]});
      # added=(${${(f)"$(     pup -f z -p 'tbody json{}' | jq -r '.[].children[9].children[3].text')"}[3,-2]});
      curl -sfLH User-Agent: ${baseurl}\&sort=def\&sortmode=ASC\&page=$((++p)) > ${tmp};
    };

    lr=${(c)#results};
    for q ( {1..${results}} ) {
      # ((${(c)#edition[q]}   > le)) && le=${(c)#edition[q]};
      ((${(c)#publisher[q]} > lp)) && lp=${(c)#publisher[q]};
      ((${(c)#author[q]}    > la)) && la=${(c)#author[q]};
      ((${(c)#length[q]}    > ll)) && ll=${(c)#length[q]};
      ((${(c)#size[q]}      > ls)) && ls=${(c)#size[q]};
      ((${(c)#format[q]}    > lf)) && lf=${(c)#format[q]};
      ((${(c)#language[q]}  > lL)) && lL=${(c)#language[q]};
    };
    le=3;
    ((la > COLUMNS / 3)) && la=$((COLUMNS / 3));
    ((lp > COLUMNS / 4)) && lp=$((COLUMNS / 4));
    lt=$((COLUMNS - lr - 1 - 1 - le - 1 - lp - 1 - 4 - 1 - lL - 1 - la - 1 - ll - 1 - ls - 1 - lf)); 

    while { true } {
      c=$(for q ( {1..${results}} ) {
        printf "%.${lr}d %b%-${lt}.${lt}s %-${le}.${le}s %b%-${lp}.${lp}s %b%-4.4s %b%-${la}.${la}s %b%${lL}.${lL}s %b%${ll}.${ll}s %b%${ls}.${ls}s %b%-${lf}.${lf}s\n" \
          $q \
          '\033[37;1m' ${title[q]:- } \
                       ${edition[q]:/null/ } \
          '\033[36;1m' ${publisher[q]:/null/ } \
          '\033[35;1m' ${year[q]:/null/ } \
          '\033[33;1m' ${author[q]:- } \
          '\033[30;1m' ${language[q]:/null/ } \
          '\033[31;1m' ${length[q]:/null/ } \
          '\033[34;1m' ${size[q]:/null/ } \
          '\033[32;1m' ${format[q]:/null/ };
      } | fzy -l $LINES | cut -d ' ' -f 1) || break;
      ((c > 0 && c <= results)) && {
        while { true } {
          clear;
          case $(nl -n ln <<< ${(F)mirror} | fzy | cut -d ' ' -f 1) {
            (1) url+=($(curl -sfLH User-Agent: ${mirror[1]}${md5[c]} | pup -p 'div#download a attr{href}' | fzy)) && ext+=(${(L)format[c]}) || read -sk1 "?${n}This mirror does not contain ${md5[c]}, select another.";;
            (2) url+=($(curl -sfLH User-Agent: ${mirror[2]}${md5[c]} | pup -p ':parent-of(h2) attr{href}'))       && ext+=(${(L)format[c]}) || read -sk1 "?${n}This mirror does not contain ${md5[c]}, select another.";;
            (3) read -sk1 "?${n}FIXME";; # url+=($(curl -sfLH User-Agent: ${mirror[3]}${md5[c]} | pup -p '...'))
            (4) read -sk1 "?${n}FIXME";; # url+=($(curl -sfLH User-Agent: ${mirror[4]}${md5[c]} | pup -p '...'))
            (*) break;;
          };
        };
      };
    };

    q=0;
    for n ( ${url} ) {
      [[ ${n} =~ "\.${ext[++q]}$" ]] && {
        [[ ${n} =~ '\?filename=' ]] && wget -nc -O ~/Downloads/${n#*=} ${n} || wget -nc -P ~/Downloads/ ${n};
      } || {
        wget -nc -O ~/Downloads/$(tr -cd '[:alnum:]' < /dev/urandom | head -c 8).${ext[q]} ${n};
      };
    };
  ;;
  (2)
    baseurl+=scimag/;
    baseurl+=\?q=${query// /+};
  ;;
  (3)
    typeset -i results pages lr lt la ls ll p c q;
    typeset -a mirror title author md5 language series sizeformat formats ext url langs format lang;

    formats=(epub mobi azw azw3 fb2 pdf rtf txt);
    baseurl+=fiction/;
    langs=(${(f)"$(curl -sfLH User-Agent: ${baseurl} | pup -p 'select[name=language] option attr{value}')"});
    baseurl+=\?q=${query// /+};
    mirror=(
      http://library.lol/fiction/
      http://libgen.lc/foreignfiction/ads.php\?md5=
      http://b-ok.cc/md5/
    );

    menu -m 4b -t 2b 'Field_to_search: ' \
      '* any' \
      '1 title' \
      '2 authors' \
      '3 series';
    case $(read -sek1 "?${n}") {
      (1) baseurl+=\&criteria=title;;
      (2) baseurl+=\&criteria=authors;;
      (3) baseurl+=\&criteria=series;;
      (*) baseurl+=\&criteria=;;
    };

    [[ $(read -seq "?${n}Query uses wildcards [y*]?> ") == y ]] && baseurl+=\&wildcard=1;

    format=($(fzy -l $LINES -p 'Format?> ' <<< ${(F)formats}));
    baseurl+=\&format=${format:*formats};

    curl -sfLH User-Agent: ${baseurl} > ${tmp};

    lang=($(fzy -l $LINES -p 'Language?> ' <<< ${(F)langs}));
    lang=${lang:*langs};
    baseurl+=\&language=${lang};

    [[ $(pup -f ${tmp} 'p text{}' | tail -n 1) == 'No files were found.' ]] && { printf 'No files found.'; return 1 };
    pages=$(pup -f ${tmp} '.page_selector text{}' | head -n 1 | cut -d ' ' -f 4);
    results=${${"$(pup -f ${tmp} '.catalog_paginator [style=float:left] text{}' | head -n 1)"%% files found}#* }; # retarded: ' '  U+00A0  160    c2 a0       &nbsp;     NO-BREAK SPACE (Space_Separator)
    ((results == 0)) && { printf 'No results.\n'; return 1 };
    ((results < 3)) && results=3;

    ((pages > 4)) && {
      printf '%s\n' "${results} results over ${pages} pages.";
      read -r "p?${n}Pages to show> ";
      ((p > 0 && p <= pages)) && {
        ((p == pages)) || {
          results=$((p * 25))
          pages=${p};
        };
      } || {
        printf '%s\n' 'Invalid selection.' 'Showing first 100 results only.';
        pages=4;
        results=100;
      };
    };

    for p ( {1..${pages}} ) {
      author+=(${(f)"$(    pup -p -f ${tmp} 'tbody td:nth-child(1) text{}' | perl -pe 'BEGIN {undef $/} s/(\w.+)\n(\w.+)/$2 $1/mg; s/(\S)\n(\S)/$1 $2/mg; s/\s{2,}/\n/mg; s/(.+?), (.+)/$2 $1/g')"});
      md5+=(${${(f)"$(     pup -p -f ${tmp} 'tbody td:nth-child(6) li:first-of-type a attr{href}')"}##*/});
      title+=(${(f)"$(     pup -p -f ${tmp} 'tbody td:nth-child(3) text{}')"});
      series+=(${(f)"$(    pup -p -f ${tmp} 'tbody td:nth-child(2) json{}' | jq -r '.[].text')"});
      sizeformat+=(${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(5) text{}')"});
      [[ -n ${lang} ]] ||
      language+=(${(f)"$(  pup -p -f ${tmp} 'tbody td:nth-child(4) text{}')"});
      curl -sfLH User-Agent: ${baseurl}\&page=$((++p)) > ${tmp};
    };

    lr=${(c)#results};
    for q ( {1..${results}} ) {
      ((${(c)#series[q]}   > ls)) && ls=${(c)#series[q]};
      ((${(c)#author[q]}   > la)) && la=${(c)#author[q]};
      [[ -n ${lang} ]] ||
      ((${(c)#language[q]} > ll)) && ll=${(c)#language[q]};
    };
    lt=$((COLUMNS - lr - 1 - 1 - ls - 1 - la - 1 - ll - 10 - 6));

    while { true } {
      c=$(for q ( {1..${results}} ) {
        printf "%.${lr}d %b%-${lt}.${lt}s %b%-${ls}.${ls}s %b%-${la}.${la}s %b%${ll}.${ll}s%b%10.10s%b%6.6s\n" \
          $q \
          '\033[37;1m' ${title[q]:- } \
          '\033[36;1m' ${series[q]:/null/ } \
          '\033[33;1m' ${author[q]:- } \
          '\033[31;1m' ${language[q]:- } \
          '\033[34;1m' ${${sizeformat[q]#* / }:- } \
          '\033[32;1m' ${${sizeformat[q]% / *}:- };
      } | fzy -l $LINES | cut -d ' ' -f 1) || break;
      ((c > 0 && c <= results)) && {
        while { true } {
          clear;
          case $(nl -n ln <<< ${(F)mirror} | fzy | cut -d ' ' -f 1) {
            (1) url+=($(curl -sfLH User-Agent: ${mirror[1]}${md5[c]} | pup -p 'div#download a attr{href}' | fzy)) && ext+=(${(L)sizeformat[c]% / *}) || read -sk1 "?${n}This mirror does not contain ${md5[c]}, select another.";;
            (2) url+=($(curl -sfLH User-Agent: ${mirror[2]}${md5[c]} | pup -p ':parent-of(h2) attr{href}'))       && ext+=(${(L)sizeformat[c]% / *}) || read -sk1 "?${n}This mirror does not contain ${md5[c]}, select another.";;
            (3) read -sk1 "?${n}FIXME";; # url+=($(curl -sfLH User-Agent: ${mirror[3]}${md5[c]} | pup -p '')); ext+=(${(L)sizeformat[c]% / *});;
            (*) break;;
          };
        };
      };
    };

    q=0;
    for n ( ${url} ) {
      [[ ${n} =~ "\.${ext[++q]}$" ]] && {
        [[ ${n} =~ '\?filename=' ]] && wget -nc -O "~/Downloads/${n#*=}" ${n} || wget -nc -P ~/Downloads/ ${n};
      } || {
        wget -nc -O ~/Downloads/$(tr -cd '[:alnum:]' < /dev/urandom | head -c 8).${ext[q]} ${n};
      };
    };
  ;;
  (4)
    typeset -i results p pages lr lt li lv lp ld q;
    typeset -a title issue volume publisher language date issuehash serieshash url file;
    baseurl=libgen.lc/comics/index.php\?s=${query// /+}\&res=100\&sorted=1;
    [[ $(read -seq "?${n}Query uses wildcards [y*]?> ") == y ]] && baseurl+=\&mask=1; printf '\n';

    menu -m 4b -t 2b 'Search_for: ' \
      '* all FIXME' \
      '1 series' \
      '2 issues' \
      '3 files FIXME';
    case $(read -sek1 "?${n}") {
      (1) baseurl+=\&show=1;;
      (2) baseurl+=\&show=2;;
      (3) read -sk1 "?${n}FIXME"; return 1;; # baseurl+=\&show=3;;
      (*) read -sk1 "?${n}FIXME"; return 1;; # baseurl+=\&show=0;;
    };

    curl -sfLH User-Agent: ${baseurl} > ${tmp};
    results=$(pup -p -f ${tmp} 'font[size=1]:contains("results") text{}' | pcre2grep -o1 'Found.*?(\d+).*results');
    ((results == 0)) && { printf 'No results.\n'; return 1 };
    ((results < 101)) && { pages=1; ((results < 3)) && results=3 } || { pages=$((results / 100)); ((results % 100 == 0)) || pages=$((pages + 1)) };

    ((pages > 2)) && {
      printf '%s\n' "${results} results over ${pages} pages.";
      read -r "p?${n}Pages to show> ";
      ((p > 0 && p <= pages)) && {
        ((p == pages)) || {
          results=$((p * 100))
          pages=${p};
        };
      } || {
        printf '%s\n' 'Invalid selection.' 'Showing first 200 results only.';
        pages=2;
        results=200;
      };
    };

    case ${(M)baseurl%?} {
      (2)
        for p ( {1..${pages}} ) {
          issuehash+=(${(f)"$(             pup -p -f ${tmp} 'tbody a[href^=seriestable.php?issue_hash]  attr{href}')"});
          serieshash+=(${(f)"$(            pup -p -f ${tmp} 'tbody a[href^=seriestable.php?series_hash] attr{href}')"});
          title+=(${(f)"$(                 pup -p -f ${tmp} 'tbody a[href^=seriestable.php?series_hash] text{}')"});
          issue+=(${${(s.Issue: .)"$(      pup -p -f ${tmp} 'tbody td:contains("Issue: ") text{}'     | tr -d '\n')"}%Volume:*});
          volume+=(${${${(s.Volume: .)"$(    pup -p -f ${tmp} 'tbody td:contains("Volume: ") text{}'  | tr -d '\n')"}%% *Issue:*}});
          date+=(${(s.Year: .)"$(          pup -p -f ${tmp} 'tbody :contains("Year: ") text{}'        | tr -d '\n')"});
          language+=(${(s.Language: .)"$(  pup -p -f ${tmp} 'tbody td:contains("Language: ") text{}'  | tr -d '\n')"});
          publisher+=(${(s.Publisher: .)"$(pup -p -f ${tmp} 'tbody td:contains("Publisher: ") text{}' | tr -d '\n')"});
          curl -sfLH User-Agent: ${baseurl}\&page=$((++p)) > ${tmp};
        };
        ;;
      (1)
        for p ( {1..${pages}} ) {
          serieshash+=(${(f)"$(            pup -p -f ${tmp} 'tbody a[href^=seriestable.php?series_hash] attr{href}')"});
          title+=(${(f)"$(                 pup -p -f ${tmp} 'tbody a[href^=seriestable.php?series_hash] text{}')"});
          issue+=(${(s.Issues: .)"$(       pup -p -f ${tmp} 'tbody :contains("Issues: ") text{}'      | tr -d '\n')"});
          volume+=(${(s.Volume: .)"$(      pup -p -f ${tmp} 'tbody :contains("Volume: ") text{}'      | tr -d '\n')"});
          date+=(${(s,Publ. Period: ,)"$(  pup -p -f ${tmp} 'tbody :contains("Publ. Period: ") text{}'| tr -d '\n')"});
          language+=(${(s.Language: .)"$(  pup -p -f ${tmp} 'tbody :contains("Language: ") text{}'    | tr -d '\n')"});
          publisher+=(${(s.Publisher: .)"$(pup -p -f ${tmp} 'tbody :contains("Publisher: ") text{}'   | tr -d '\n')"});
          curl -sfLH User-Agent: ${baseurl}\&page=$((++p)) > ${tmp};
        };
        ;;
    };

    lr=${(c)#results};
    for q ( {1..${results}} ) {
      ((${(c)#issue[q]}     > li)) && li=${(c)#issue[q]};
      ((${(c)#volume[q]}    > lv)) && lv=${(c)#volume[q]};
      ((${(c)#publisher[q]} > lp)) && lp=${(c)#publisher[q]};
      ((${(c)#date[q]}      > ld)) && ld=${(c)#date[q]};
    };
    lt=$((COLUMNS - lr - 1 - 1 - lv - 1 - li - 1 - lp - 1 - 2 - 1 - ld));

    while { true } {
      c=$(for q ( {1..${results}} ) {
        printf "%.${lr}d %b%-${lt}.${lt}s %b%-${lv}.${lv}s %b%-${li}.${li}s %b%-${lp}.${lp}s %b%2.2s %b%-${ld}.${ld}s\n" \
          $q \
          '\033[37;1m' ${title[q]:- } \
          '\033[34;1m' ${volume[q]:- } \
          '\033[32;1m' ${issue[q]:- } \
          '\033[33;1m' ${publisher[q]:- } \
          '\033[35;1m' ${(U)language[q]:- } \
          '\033[31;1m' ${date[q]:- };
      } | fzy -l $LINES | cut -d ' ' -f 1) || break;

      # DOWNLOADS LARGEST EXISTING ISSUE FILES BY DEFAULT
      ((c > 0 && c <= results)) && {
        if [[ ${(M)baseurl%?} == 1 ]] || { [[ ${(M)baseurl%?} == 2 ]] && [[ $(read -seq "?${n}Download entire series [y*]? ") == y ]] } {
          curl -sfLH User-Agent: http://libgen.lc/comics/${serieshash[c]} > ${tmp} || break;
          q=0;
          for n ( ${(f)"$(pup -p -f ${tmp} 'tbody tr tr:first-child a[href^=get] attr{href}')"} ) {
            url+=(http://libgen.lc/comics/${n});
            ((++q));
          };
          typeset -Z ${(c)#${q}}; q=0;
          for n ( ${${(f)"$(pup -p -f ${tmp} 'tbody tr tr:first-child a[href^=get] text{}')"}%/*} ) {
            file+=("${title[c]}-${volume[c]}-${issue[c]}.$((++q)).${n}");
          };
        } elif [[ ${(M)baseurl%?} == 2 ]] {
          curl -sfLH User-Agent: http://libgen.lc/comics/${issuehash[c]} > ${tmp} || break;
          file+=("${title[c]}-${volume[c]}-${issue[c]}.${${(f)"$(pup -f ${tmp} 'a[href^=get] text{}')"}[1]%/*}");
          url+=(http://libgen.lc/comics/${${(f)"$(pup -f ${tmp} 'a[href^=get] attr{href}')"}[1]});
        };
      };
    };

    q=0;
    for n ( ${url} ) {
      wget -nc -O ~/Downloads/${file[++q]} ${n};
    };
  ;;
  (5)
    typeset -i pages results lr lt ls lf lS lp ln ll q p c;
    typeset -a title format length language pubdate size
    baseurl=http://libgen.lc/standarts/index.php\?s=${query// /%20};

    curl -sfLH User-Agent: ${baseurl} > ${tmp};
    results=$(pup -p -f ${tmp} | pcre2grep -o1 'Found.*?(\d+).*results');
    ((results == 0)) && { printf 'No results.\n'; return 1 };
    ((results < 26)) && { pages=1; ((results < 3)) && results=3 } || { pages=$((results / 25)); ((results % 25 == 0)) || pages=$((pages + 1)) };

    ((pages > 4)) && {
      printf '%s\n' "${results} results over ${pages} pages.";
      read -r "p?${n}Pages to show> ";
      ((p > 0 && p <= pages)) && {
        ((p == pages)) || {
          results=$((p * 25))
          pages=${p};
        };
      } || {
        printf '%s\n' 'Invalid selection.' 'Showing first 100 results only.';
        pages=4;
        ((results >= 100 )) && results=100;
      };
    };

    for p ( {1..${pages}} ) {
      number+=(${(f)"$(  pup -p -f ${tmp} 'tbody tr td[width=200] b text{}')"});
      md5+=(${(f)"$(     pup -p -f ${tmp} 'tbody td:nth-child(2) td:nth-child(1) a text{}')"});
      format+=(${${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(2) td:nth-child(3) text{}')"}//Extension: (#b)(*);/${match[1]}});
      size+=($(numfmt --to=iec <<< ${(F)${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(2) td:nth-child(2) text{}')"}//Filesize: (#b)(+([0-9]));/${match[1]}}));
      Status+=(${(f)"$(  pup -p -f ${tmp} 'tbody td:nth-child(3) text{}' | pcre2grep -M -o1 'Status:\n(.*)')"});
      length+=(${(f)"$(  pup -p -f ${tmp} 'tbody td:nth-child(3) text{}' | pcre2grep -M -o1 'Pages:\n(.*)')"});
      language+=(${(f)"$(pup -p -f ${tmp} 'tbody td:nth-child(3) text{}' | pcre2grep -M -o1 'Language:\n(.*)')"});
      title+=(${(f)"$(   pup -p -f ${tmp} 'tbody td[width=400] text{}'   | pcre2grep -M -o1 '(.*)\nMD5:')"});
      pubdate+=(${(f)"$( pup -p -f ${tmp} 'tbody td:nth-child(1) tr:nth-child(3) td:nth-child(2) text{}')"});
      curl -sfLH User-Agent: ${baseurl}\&page=$((++p)) > ${tmp};
    };

    lr=${(c)#results};
    for q ( {1..${results}} ) {
      ((${(c)#size[q]}    > ls)) && ls=${(c)#size[q]};
      ((${(c)#format[q]}  > lf)) && lf=${(c)#format[q]};
      ((${(c)#Status[q]}  > lS)) && lS=${(c)#Status[q]};
      ((${(c)#number[q]}  > ln)) && ln=${(c)#number[q]};
      ((${(c)#length[q]}  > ll)) && ll=${(c)#length[q]};
      ((${(c)#pubdate[q]} > lp)) && lp=${(c)#pubdate[q]};
    };
    lt=$((COLUMNS - lr - 1 - 1 - ln - 1 - lp - 1 - lS - 1 - ll - 1 - ls - 1 - lf));

    while { true } {
      c=$(for q ( {1..${results}} ) {
        printf "%.${lr}d %b%-${lt}.${lt}s %b%-${ln}.${ln}s %b%-${lp}.${lp}s %b%${lS}.${lS}s %b%${ll}.${ll}s %b%${ls}.${ls}s %b%${lf}.${lf}s\n" \
          $q \
          '\033[37;1m' ${title[q]:- } \
          '\033[34;1m' ${number[q]:- } \
          '\033[35;1m' ${pubdate[q]:- } \
          '\033[36;1m' ${Status[q]:- } \
          '\033[30;1m' ${length[q]:- } \
          '\033[33;1m' ${size[q]:- } \
          '\033[31;1m' ${format[q]:- };
      } | fzy -l $LINES | cut -d ' ' -f 1) || break;
      ((c > 0 && c <= results)) && url+=($(curl -sfLH User-Agent: http://libgen.lc/standarts/get.php\?md5=${md5[c]})) && ext+=(${(L)format[c]});
    };

    q=0;
    for n ( ${url} ) {
      wget -nc -O ~/Downloads/$(tr -cd '[:alnum:]' < /dev/urandom | head -c 8).${ext[q]} ${n};
    };
  ;;
  (6)
    baseurl=http://magzdb.org/\?q=${query// /+};
    return 0;
  ;;
  (*) return 1;;
};

rm -f ${tmp} &>/dev/null

# FULL TEXT SEARCH
# https://b-ok.cc/fulltext/
